{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cap 1: Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Uma rede complexa real: Wikipédia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import wikipedia # a instalar\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A linguagem de Wikipedia : português\n",
    "wikipedia.set_lang(\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no raiz\n",
    "RAIZ = \"Fortaleza\".title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# páginas excluidas\n",
    "EXCL = (\"International Standard Serial Number\",\n",
    "\"International Standard Book Number\",\n",
    "\"National Diet Library\",\n",
    "\"International Standard Name Identifier\",\n",
    "\"International Standard Book Number (Identifier)\",\n",
    "\"Pubmed Identifier\", \n",
    "\"Pubmed Central\",\n",
    "\"Digital Object Identifier\", \n",
    "\"Arxiv\",\n",
    "\"Proc Natl Acad Sci Usa\", \n",
    "\"Bibcode\",\n",
    "\"Library Of Congress Control Number\", \n",
    "\"Jstor\",\n",
    "\"OpenStreetMap\",\n",
    "\"Wikimapia\",\n",
    "\"Instituto Nacional de Meteorologia\",\n",
    "\"Instituto Brasileiro de Geografia e Estatística\",\n",
    "\"Coeficiente de Gini\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista de nos por explorar\n",
    "pend_lst = [(0, RAIZ)] # O vértice RAIZ está na camada 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conjunto de nos que ainda devem ser explorados\n",
    "pend_cnj = set(RAIZ) # Só RAIZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conjunto de nos que ja foram explorados\n",
    "feito_cnj = set() # Nehum nó explorado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "camada, pag = pend_lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Fortaleza\n",
      "1 13 De Abril\n",
      "1 15 De Agosto\n",
      "1 1726\n",
      "1 1884\n",
      "1 19 De Março\n",
      "1 1 De Abril\n",
      "1 2019 No Brasil\n",
      "1 25 De Março\n",
      "1 89 Fm\n",
      "1 8 De Dezembro\n",
      "1 Am Cidade\n",
      "1 A Igreja De Jesus Cristo Dos Santos Dos Últimos Dias\n",
      "1 Abolicionismo No Brasil\n",
      "1 Abril Despedaçado (Filme)\n",
      "1 Academia Brasileira De Letras\n",
      "1 Academia Cearense De Letras\n",
      "1 Academia De Letras\n",
      "1 Acaraú\n",
      "1 Acidente Rodoviário\n",
      "1 Acopiara\n",
      "1 Acorizal\n",
      "1 Acre\n",
      "1 Adolfo Caminha\n",
      "1 Adolfo Herbster\n",
      "1 Aeroporto Internacional Pinto Martins\n",
      "1 Aeroporto Internacional De Fortaleza\n",
      "1 Agricultura\n",
      "1 Agropecuária\n",
      "1 Alagoas\n",
      "1 Alberto Nepomuceno\n",
      "1 Alcântara (Maranhão)\n",
      "1 Aldeamento\n",
      "1 Aldeota\n",
      "1 Alfabetização\n",
      "1 Algodão\n",
      "1 Alimento\n",
      "1 Almas (Tocantins)\n",
      "1 Aloísio Lorscheider\n",
      "1 Alta Cultura\n",
      "1 Altitude\n",
      "1 Alvorada (Rio Grande Do Sul)\n",
      "1 Amapá\n",
      "1 Amarelos\n",
      "1 Amazonas\n",
      "1 Amazônia\n",
      "1 Amelinha\n",
      "1 América Latina\n",
      "1 Ananindeua\n",
      "1 Andaraí\n",
      "1 Angra Dos Reis\n",
      "1 Antonina\n",
      "1 António José Da Silva Paulet\n",
      "1 Antônio Bezerra (Fortaleza)\n",
      "1 Antônio Cambraia\n",
      "1 Antônio Pinto Nogueira Acioly\n",
      "1 Anápolis\n",
      "1 Aparecida De Goiânia\n",
      "1 Aquiraz\n",
      "1 Aracaju\n",
      "1 Aracati\n",
      "1 Araraquara\n",
      "1 Araripe Júnior\n",
      "1 Aratuípe\n",
      "1 Arcebispo\n",
      "1 Areia (Paraíba)\n",
      "1 Areias (São Paulo)\n",
      "1 Argila\n",
      "1 Arica (Comuna)\n",
      "1 Arquidiocese De Fortaleza\n",
      "1 Arquitetura\n",
      "1 Arquitetura Do Neoclassicismo\n",
      "1 Arquitetura Eclética\n",
      "1 Arquitetura Gótica\n",
      "1 Arquitetura Românica\n",
      "1 Arquivo Nacional (Brasil)\n",
      "1 Arquivos Nacionais E Administração De Documentos\n",
      "1 Arraial D'Ajuda\n",
      "1 Arraial Do Pontal\n",
      "1 Arraias\n",
      "1 Arrecife\n",
      "1 Artes Marciais\n",
      "1 Artes Marciais Mistas\n",
      "1 Artes Visuais\n",
      "1 Artesanato\n",
      "1 Asfalto\n",
      "1 Assalto Ao Banco Central\n",
      "1 Assalto Ao Banco Central Do Brasil Em Fortaleza\n",
      "1 Assembleia Legislativa Do Ceará\n",
      "1 Associação Comercial Do Ceará\n",
      "1 Associação Nacional De História\n",
      "1 Assunção\n",
      "1 Atletismo\n",
      "1 Atlântico Sul Fm\n",
      "1 Autocarro\n",
      "1 Automobilismo\n",
      "1 Automóvel\n",
      "1 Automóvel Utilitário\n",
      "1 Autódromo Internacional Virgílio Távora\n",
      "1 Ave\n",
      "1 Avellaneda (Partido)\n",
      "1 Avenida Beira Mar (Fortaleza)\n",
      "1 Avenida Dom Manuel\n",
      "1 Avenida Duque De Caxias\n",
      "1 Avenida Monsenhor Tabosa\n",
      "1 Avenida Santos Dumont (Fortaleza)\n",
      "1 Avenida Washington Soares\n",
      "1 Avenida Do Imperador\n",
      "1 Aviões Do Forró\n",
      "1 Açoriano\n",
      "1 Bicbanco\n",
      "1 Br-020\n",
      "1 Br-116\n",
      "1 Br-222\n",
      "1 Bahia\n",
      "1 Bahía Blanca\n",
      "1 Baião De Dois\n",
      "1 Bananal\n",
      "1 Bancesa\n",
      "1 Banco Bmc\n",
      "1 Banco Central Do Brasil\n",
      "1 Banco Palmas\n",
      "1 Banco Comunitário\n",
      "1 Banco Do Estado Do Ceará\n",
      "1 Banco Do Nordeste\n",
      "1 Bandnews Fm\n",
      "1 Bandeira De Fortaleza\n",
      "1 Baobá\n",
      "1 Barbalha\n",
      "1 Barcelos (Amazonas)\n",
      "1 Barquisimeto\n",
      "1 Barra\n",
      "1 Barra Do Ceará\n",
      "1 Barra Do Ribeiro\n",
      "1 Barranqueras\n",
      "1 Barão De Cocais\n",
      "1 Barão De Melgaço\n",
      "1 Base Aérea De Fortaleza\n",
      "1 Base Virtual Internacional De Autoridade\n",
      "1 Basquetebol\n",
      "1 Batavos\n",
      "1 Batoidea\n",
      "1 Beach Park\n",
      "1 Beberibe\n",
      "1 Bela Vista\n",
      "1 Belchior\n",
      "1 Belford Roxo\n",
      "1 Bella Vista Norte\n",
      "1 Belo Horizonte\n",
      "1 Belo Vale\n",
      "1 Belém (Pará)\n",
      "1 Benfica (Fortaleza)\n",
      "1 Biblioteca Pública Estadual Do Ceará\n",
      "1 Biblioteca Pública Governador Menezes Pimentel\n",
      "1 Biblioteca Pública Municipal Dolor Barreira\n",
      "1 Bicicletar\n",
      "1 Bienal Internacional Do Livro Do Ceará\n",
      "1 Bilhete Único\n",
      "1 Bilro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jossian/.local/lib/python3.10/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /home/jossian/.local/lib/python3.10/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nao pude carregar Bio-Manguinhos\n",
      "1 Bio-Manguinhos\n",
      "1 Blues\n",
      "1 Boa Viagem (Ceará)\n",
      "1 Boa Vista (Roraima)\n",
      "1 Bobó De Camarão\n",
      "1 Bode Ioiô\n",
      "1 Bogotá\n",
      "1 Bom Jesus Da Lapa\n",
      "1 Borba (Amazonas)\n",
      "1 Bordado\n",
      "1 Bosque\n",
      "1 Bovinos\n",
      "1 Bovril\n",
      "1 Boémia (Estilo De Vida)\n",
      "1 Bradesco\n",
      "1 Bragado (Buenos Aires)\n",
      "1 Bragança (Pará)\n",
      "1 Brancos\n",
      "1 Brasil\n",
      "1 Brasil Colônia\n",
      "1 Brasão De Fortaleza\n",
      "1 Brasília\n",
      "1 Brega\n",
      "1 Brejo Da Madre De Deus\n",
      "1 Budismo\n",
      "1 Buenos Aires\n",
      "1 Bus Rapid Transit\n",
      "1 Ce-025\n",
      "1 Ce-040\n",
      "1 Ce-060\n",
      "1 Ce-065\n",
      "1 Ce-085\n"
     ]
    }
   ],
   "source": [
    "while camada < 2:\n",
    "    del pend_lst[0]\n",
    "    feito_cnj.add(pag)\n",
    "    print(camada, pag)\n",
    "    try:\n",
    "        wiki = wikipedia.page(pag) \n",
    "        # pode ser carregada a pagina?\n",
    "        wiki.links \n",
    "        # bug não dá certo se a página não tem links\n",
    "    except:\n",
    "        camada, pag = pend_lst[0]\n",
    "        print('Nao pude carregar', pag)\n",
    "        continue\n",
    "    for link in wiki.links:\n",
    "        link = link.title()\n",
    "        if link not in EXCL and not link.startswith(\"Lista de\"):\n",
    "            if link not in pend_cnj and link not in feito_cnj:\n",
    "                pend_lst.append((camada + 1, link))\n",
    "                pend_cnj.add(link)\n",
    "            F.add_edge(pag, link)\n",
    "    camada, pag = pend_lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{} nos, {} arestas\".format(F.order(), nx.number_of_edges(F)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva a rede\n",
    "with open('wikifortaleza.p', 'wb') as f:\n",
    "    pickle.dump(F, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apagamos laços\n",
    "F.remove_edges_from(nx.selfloop_edges(F))\n",
    "print(\"{} nós , {} arestas\".format(F.order(), nx.number_of_edges(F)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos duplicados - Plurais\n",
    "duplicados = [(vert, vert + \"s\") for vert in F if vert + \"s\" in F]\n",
    "for dup in duplicados:\n",
    "    F = nx.contracted_nodes(F, *dup, self_loops = False)\n",
    "    \n",
    "print(\"{} nós, {} arestas\".format(F.order(), nx.number_of_edges(F)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos duplicados - \" - \"\n",
    "duplicados = [(x,y) for x , y in [(vert, vert.replace(\"-\", \" \")) for vert in F] if x!=y and y in F]\n",
    "for dup in duplicados:\n",
    "    F = nx.contracted_nodes(F, *dup, self_loops=False)\n",
    "    \n",
    "print(\"{} nós, {} arestas\".format(F.order(), nx.number_of_edges(F)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva a rede\n",
    "with open(\"wikifortaleza - semdup.p\", 'wb') as f:\n",
    "    pickle.dump (F , f )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(F, with_labels = \"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Densidade : \", nx.density(F))\n",
    "print(\"Coeficiente de agrupamento : \", nx.transitivity(F))\n",
    "print(\"Reciprocidade :\" , nx.reciprocity(F))\n",
    "hgrauF = nx.degree_histogram(F)\n",
    "grausF = np.linspace(0 , len(hgrauF), len(hgrauF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Networkx ainda não tem uma função como degree_histogram () para arestas\n",
    "# saintes ou entrantes .\n",
    "hgrauinF = [0]*len(hgrauF)\n",
    "for ver, grau in F.in_degree():\n",
    "    hgrauinF[grau] = hgrauinF[grau] + 1\n",
    "    hgrauouF = [0]*len(hgrauF)\n",
    "for ver, grau in F.out_degree():\n",
    "    hgrauouF[grau] = hgrauouF[grau] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.loglog(grausF,hgrauF,'b*',label='Grau')\n",
    "plt.loglog(grausF,hgrauinF,'r^',label='Grau entrante')\n",
    "plt.loglog(grausF,hgrauouF,'k+',label='Grau sainte')\n",
    "plt.xlabel('grau')\n",
    "plt.ylabel('frequência')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nucleo = [vert for vert, grau in F.degree() if grau >= 10]\n",
    "N = nx.subgraph(F, nucleo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimina o atributo \"contraction\" dos nos\n",
    "for (n,d) in N.nodes(data=True):\n",
    "    try:\n",
    "        del d[\"contraction\"]\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimina todos os atributos das arestas\n",
    "for n1, n2, d in N.edges(data=True):\n",
    "    d.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{} nos, {} arestas\".format(len(N), nx.number_of_edges(N)))\n",
    "nx.write_graphml(N, \"wiki-fortaleza.graphml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
